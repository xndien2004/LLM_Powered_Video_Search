# LLM-Powered Video Search: A Comprehensive Multimedia Retrieval System

<p align="center">
  <em>An intelligent video retrieval system leveraging Large Language Models (LLMs) and multimodal search, developed for the AIC2024 competition and accepted at the international SOICT 2024 conference.</em>
</p>

![Static Badge](https://img.shields.io/badge/python->=3.10-blue)
![Static Badge](https://img.shields.io/badge/django-3.x-blue)
![Static Badge](https://img.shields.io/badge/clip-v1.0-blue)
![Static Badge](https://img.shields.io/badge/tfidf-1.5.2-blue)

<details>
  <summary>Table of Contents</summary>

  - [ğŸ“ Overview](#-overview)
  - [ğŸ¯ Features](#-features)
  - [ğŸ¤– Tech Stack](#-tech-stack)
  - [ğŸš€ Setup and Usage](#-setup-and-usage)
  - [ğŸ¬ Demo](#-demo)
  - [ğŸ‘£ Workflow](#-workflow)
  - [ğŸ“ App Structure](#-app-structure)
  - [ğŸ§‘â€ğŸ’» Contributors](#-contributors)

</details>

## ğŸ“ Overview 
The `LLM-Powered Video Search System` is an advanced multimodal video search solution that leverages Large Language Models (LLMs) to enhance video retrieval through text, image, and metadata queries. This project was developed for the [AIC2024](https://aichallenge.hochiminhcity.gov.vn/) competition and has been accepted at the international [SOICT 2024](https://soict.org/) conference, aiming to provide an intelligent and efficient video search system. Details about the paper can be found on [Springer](https://www.springer.com/).

## ğŸ¯ Features

1. **Multimodal Search Capabilities**
   - **Text-based search:** Supports ASR (Automatic Speech Recognition), OCR, captions, and descriptive image queries for improved accuracy.
   - **Image-based search:** Enables users to find specific video segments based on images.
   - **Metadata-based search:** Provides a 7x7 matrix for tagging objects and color attributes for contextual search.

2. **LLM-Powered Interaction**
   - Integrates LLMs (e.g., GPT-4) to handle natural language queries and deliver relevant search results tailored to the context.

3. **User-Friendly Interface**
   - A responsive user interface allows users to view results as keyframes or full video segments and interact with detailed metadata.

## ğŸ¤– Tech Stack

- **Back-end**: Django
- **Core Technologies**: CLIP, Faiss, TFIDF
- **Supporting Technologies**: OpenCV, PyTorch, Transformers
- **Development Tools**: Docker, Git, Jupyter Notebook

## ğŸš€ Setup and Usage

1. **Clone Repository**
   ```bash
   git clone https://github.com/xndien2004/LLM_Powered_Video_Search.git
   cd AIC2024
   ```

2. **Install Dependencies**
   Ensure Python and Django are installed. Then, install other dependencies from `requirements.txt`:

   ```bash
   pip install -r requirements.txt
   ```

3. **Configure `MEDIA_ROOT`**
   Open [settings.py](./AIC/settings.py) in the `AIC/` folder and set `MEDIA_ROOT` to point to your local `media` directory:

   ```python
   MEDIA_ROOT = '/path/to/your/media'
   ```
   You can download the dataset from [Google Drive](https://drive.google.com/drive/folders/17Yab4iMAEzok0pO_czgbAkKBlaQ2ptqU) or [Kaggle](https://www.kaggle.com/datasets/tienanh2003/keyframes-v1-aic2024).

   Media for the app should be stored in the `media` directory. The structure should be as follows:
   <details>
   <summary>Media format</summary>
   ```
   media/
   â”œâ”€â”€ contexts_bin/
   â”‚   â”œâ”€â”€ npz/
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_asr.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_caption.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_number_tag.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_number.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_ocr.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_synthetic.npz
   â”‚   â”‚   â”œâ”€â”€ sparse_context_matrix_tag.npz
   â”‚   â”œâ”€â”€ pkl/
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_asr.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_caption.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_number_tag.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_number.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_ocr.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_synthetic.pkl
   â”‚   â”‚   â”œâ”€â”€ tfidf_transform_tag.pkl
   â”œâ”€â”€ faiss/
   â”‚   â”œâ”€â”€ faiss_openclip.bin
   â”‚   â”œâ”€â”€ ...
   â”œâ”€â”€ Keyframes/
   â”‚   â”œâ”€â”€ Keyframes_L01/keyframes/
   â”‚   â”‚   â”œâ”€â”€ L01_V001/
   â”‚   â”‚   â”‚   â”œâ”€â”€ 001.jpg
   â”‚   â”‚   â”‚   â”œâ”€â”€ 002.jpg
   â”‚   â”‚   â”‚   â”œâ”€â”€ ...
   â”‚   â”œâ”€â”€ ...
   â”œâ”€â”€ map-keyframes/
   â”‚   â”œâ”€â”€ L01_V001.csv
   â”‚   â”œâ”€â”€ L01_V002.csv
   â”‚   â”œâ”€â”€ ...
   â”œâ”€â”€ media-info/
   â”‚   â”œâ”€â”€ L01_V001.json
   â”‚   â”œâ”€â”€ L01_V002.json
   â”‚   â”œâ”€â”€ ...
   â”œâ”€â”€ tag/
   â”‚   â”œâ”€â”€ tag_corpus.txt
   â”œâ”€â”€ id2img_fps_extra.json
   â”œâ”€â”€ id2img_fps.json
   â”œâ”€â”€ id2video.json
   â”œâ”€â”€ map-asr.json

   ```
   </details>

4. **Verify Paths in `viewAPI.py`**
   Ensure paths in `app/viewAPI.py` are correct.

5. **Run Migrations**
   Update the database with migrations:

   ```bash
   python manage.py migrate
   ```

6. **Run the Application**
   To start the application, use:

   ```bash
   python manage.py runserver
   ```

   The app will run by default at `http://127.0.0.1:8000/`.

## ğŸ¬ Demo

- **Screenshots**: ![image](./figs/image/demo.png)

## ğŸ‘£ Workflow
![Pipeline](./figs/image/pipeline.png)
- **Data Processing**: Video data is processed using ASR or extracted via TransnetV2, then converted into image features and metadata.
![Data Processing](./figs/image/data_processing.png)
- **LLM Powered Interaction**: Natural language queries are processed by the LLM and combined with image features and metadata for relevant video retrieval.
![LLM Interaction](./figs/image/LLM.png)


## ğŸ“ App Structure
```
â”œâ”€â”€ LLM_Powered_Video_Search/
â”‚   â”œâ”€â”€ AIC/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ admin.py
â”‚   â”‚   â”œâ”€â”€ data_utils.py
â”‚   â”‚   â”œâ”€â”€ migrations/
â”‚   â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ viewAPI.py 
â”‚   â”œâ”€â”€ data_extraction/
â”‚   â”‚   â”œâ”€â”€ TransnetV2/
â”‚   â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ figs/
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ utils/
â”‚       â”œâ”€â”€ LLM/
â”‚       â”œâ”€â”€ video_retrieval/
â”‚       â”œâ”€â”€ faiss_search.py
â”‚       â”œâ”€â”€ combine_search.py
|       |...
```

## ğŸ§‘â€ğŸ’» Contributors

- [Tráº§n XuÃ¢n Diá»‡n](https://github.com/dienlamAI)
- [HoÃ ng Tiáº¿n Anh](https://github.com/HTAnh2003)
- [DÆ°Æ¡ng VÄƒn TÃ i](https://github.com/TaiDuongRepo)
